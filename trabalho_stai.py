# -*- coding: utf-8 -*-
"""Trabalho_STAI.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Qt0e4F-Itoa9y9hWdjXk-W5NQAobt-cw
"""

from google.colab import files


uploaded = files.upload()

import pandas as pd
import numpy as np

df = pd.read_csv("/content/sigfox_dataset_antwerp.csv")

print("Colunas originais:", df.columns.tolist())
df.head()

# ===============================
# PIPELINE DE ESTIMA√á√ÉO DE PATH LOSS ‚Äì URBANO ANTWERP
# ===============================

import pandas as pd
import numpy as np
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor
from xgboost import XGBRegressor
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
import matplotlib.pyplot as plt
from math import radians, cos, sin, asin, sqrt

# -------------------------------
# 1Ô∏è‚É£ CARREGAR E LIMPAR CSV
# -------------------------------
df = pd.read_csv("/content/sigfox_dataset_antwerp.csv")

# Limpar nomes de colunas
df.columns = [c.strip().replace("'", "") for c in df.columns]

# Substituir -200 por NaN
bs_cols = [c for c in df.columns if "BS" in c]
df[bs_cols] = df[bs_cols].replace(-200, np.nan)

# Mostrar resumo
print(df.head(5))
print(df.info())

# -------------------------------
# 2Ô∏è‚É£ CALCULAR DIST√ÇNCIAS (Haversine)
# -------------------------------
def haversine(lat1, lon1, lat2, lon2):
    # converte graus para radianos
    lat1, lon1, lat2, lon2 = map(radians, [lat1, lon1, lat2, lon2])
    dlat = lat2 - lat1
    dlon = lon2 - lon1
    a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlon/2)**2
    c = 2 * asin(sqrt(a))
    R = 6371000  # raio da Terra em metros
    return c * R

# cria coluna com melhor gateway e sua dist√¢ncia
df['best_bs'] = df[bs_cols].idxmax(axis=1)
df['best_rssi'] = df[bs_cols].max(axis=1)

# Placeholder: lat/lon gateways
gw_locs = {bs: (df['Latitude'].mean() + np.random.randn()*0.001,
                df['Longitude'].mean() + np.random.randn()*0.001)
           for bs in bs_cols}

df['dist_best_bs'] = df.apply(lambda row: haversine(
    row['Latitude'], row['Longitude'],
    gw_locs[row['best_bs']][0], gw_locs[row['best_bs']][1]), axis=1)

# -------------------------------
# 3Ô∏è‚É£ FSPL (baseline)
# -------------------------------
# FSPL = 20*log10(d) + 20*log10(f) + 32.44, f em MHz, d em km
f_mhz = 868  # Sigfox
df['fspl_db'] = 20*np.log10(df['dist_best_bs']/1000) + 20*np.log10(f_mhz) + 32.44

rmse_fspl = np.sqrt(mean_squared_error(df['best_rssi'], -df['fspl_db']))
print("FSPL RMSE:", rmse_fspl)

# -------------------------------
# 4Ô∏è‚É£ Log-distance model via OLS
# -------------------------------
# PL(d) = PL(d0) + 10 * n * log10(d/d0) + XœÉ
d0 = 1  # refer√™ncia em metros
X = np.log10(df['dist_best_bs']/d0).values.reshape(-1,1)
y = -df['best_rssi'].values  # path loss positivo
ols = LinearRegression().fit(X, y)
n = ols.coef_[0]
sigma = np.std(y - ols.predict(X))
print(f"Log-distance: n={n:.2f}, sigma={sigma:.2f} dB")

# -------------------------------
# 5Ô∏è‚É£ Okumura-Hata (simplificado)
# -------------------------------
# PL(dB) = 69.55 + 26.16*log10(f) - 13.82*log10(h_tx) - a(h_rx) + (44.9-6.55*log10(h_tx))*log10(d_km)
h_tx, h_rx = 30, 1.5  # metros
a_hrx = (1.1*np.log10(f_mhz)-0.7)*h_rx - (1.56*np.log10(f_mhz)-0.8)
d_km = df['dist_best_bs']/1000
df['ohata'] = 69.55 + 26.16*np.log10(f_mhz) - 13.82*np.log10(h_tx) - a_hrx + (44.9-6.55*np.log10(h_tx))*np.log10(d_km)
rmse_oh = np.sqrt(mean_squared_error(df['best_rssi'], -df['ohata']))
print("Okumura-Hata RMSE:", rmse_oh)

# -------------------------------
# 6Ô∏è‚É£ Random Forest e XGBoost
# -------------------------------
features = ['dist_best_bs']
X = df[features].fillna(0)
y = -df['best_rssi']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

rf = RandomForestRegressor(n_estimators=200, random_state=42).fit(X_train, y_train)
xgb = XGBRegressor(n_estimators=200, random_state=42).fit(X_train, y_train)

for name, model in zip(['RF', 'XGB'], [rf, xgb]):
    y_pred = model.predict(X_test)
    rmse = np.sqrt(mean_squared_error(y_test, y_pred))
    mae = mean_absolute_error(y_test, y_pred)
    r2 = r2_score(y_test, y_pred)
    print(f"{name} ‚Äì RMSE: {rmse:.2f}, MAE: {mae:.2f}, R¬≤: {r2:.2f}")

# -------------------------------
# 7Ô∏è‚É£ Ablation study
# -------------------------------
# sem gw_id, sem tempo

# -------------------------------
# 8Ô∏è‚É£ Mapas de erro e an√°lise
# -------------------------------
df['err_rf'] = y_test - rf.predict(X_test)
plt.hist(df['err_rf'], bins=30)
plt.title("Erro RF")
plt.xlabel("dB")
plt.ylabel("Frequ√™ncia")
plt.show()

# =====================================
# PIPELINE FINAL ‚Äì PATH LOSS URBANO ANTWERP
# =====================================

import pandas as pd
import numpy as np
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor
from xgboost import XGBRegressor
from sklearn.model_selection import GroupKFold
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from sklearn.preprocessing import LabelEncoder
from sklearn.cluster import DBSCAN
import matplotlib.pyplot as plt
from math import radians, cos, sin, asin, sqrt

# -------------------------------
# 1Ô∏è‚É£ CARREGAR CSV E LIMPAR
# -------------------------------
df = pd.read_csv("/content/sigfox_dataset_antwerp.csv")
df.columns = [c.strip().replace("'", "") for c in df.columns]
bs_cols = [c for c in df.columns if "BS" in c]
df[bs_cols] = df[bs_cols].replace(-200, np.nan)
df['RX Time'] = pd.to_datetime(df['RX Time'].str.replace("'", ""))

# -------------------------------
# 2Ô∏è‚É£ FEATURES TEMPORAIS
# -------------------------------
df['hour'] = df['RX Time'].dt.hour
df['dayofweek'] = df['RX Time'].dt.dayofweek

# -------------------------------
# 3Ô∏è‚É£ RECONSTRU√á√ÉO DE GATEWAYS (DBSCAN)
# -------------------------------
gw_positions = {}
for bs in bs_cols:
    temp = df[['Latitude','Longitude', bs]].dropna()
    if len(temp) < 2:
        continue
    coords = temp[['Latitude','Longitude']].values
    clustering = DBSCAN(eps=0.002, min_samples=5).fit(coords)
    labels = clustering.labels_
    for lbl in set(labels):
        if lbl == -1:
            continue
        cluster_coords = coords[labels==lbl]
        gw_positions[f"{bs}_{lbl}"] = cluster_coords.mean(axis=0)

# -------------------------------
# 4Ô∏è‚É£ ASSOCIAR MELHOR GATEWAY E DIST√ÇNCIA
# -------------------------------
def haversine(lat1, lon1, lat2, lon2):
    lat1, lon1, lat2, lon2 = map(radians, [lat1, lon1, lat2, lon2])
    dlat = lat2 - lat1
    dlon = lon2 - lon1
    a = sin(dlat/2)**2 + cos(lat1)*cos(lat2)*sin(dlon/2)**2
    c = 2 * asin(sqrt(a))
    R = 6371000
    return c * R

df['best_bs'] = df[bs_cols].idxmax(axis=1)
df['best_rssi'] = df[bs_cols].max(axis=1)

def assign_gw_cluster(row):
    best = row['best_bs']
    min_dist = np.inf
    selected = None
    for gw, pos in gw_positions.items():
        if gw.startswith(best):
            d = haversine(row['Latitude'], row['Longitude'], pos[0], pos[1])
            if d < min_dist:
                min_dist = d
                selected = gw
    return pd.Series([selected, min_dist])

df[['gw_id', 'dist_m']] = df.apply(assign_gw_cluster, axis=1)

# -------------------------------
# 5Ô∏è‚É£ MODELOS CL√ÅSSICOS
# -------------------------------
f_mhz = 868

# FSPL
df['fspl_db'] = 20*np.log10(df['dist_m']/1000+1e-6) + 20*np.log10(f_mhz) + 32.44

# Log-distance via OLS
d0 = 1
X_ols = np.log10(df['dist_m']/d0).values.reshape(-1,1)
y_ols = -df['best_rssi'].values
ols = LinearRegression().fit(X_ols, y_ols)
df['logdist'] = ols.predict(X_ols)
sigma = np.std(y_ols - df['logdist'])
print(f"Log-distance n={ols.coef_[0]:.2f}, sigma={sigma:.2f} dB")

# Okumura-Hata simplificado
h_tx, h_rx = 30, 1.5
a_hrx = (1.1*np.log10(f_mhz)-0.7)*h_rx - (1.56*np.log10(f_mhz)-0.8)
d_km = df['dist_m']/1000
df['ohata'] = 69.55 + 26.16*np.log10(f_mhz) - 13.82*np.log10(h_tx) - a_hrx + (44.9-6.55*np.log10(h_tx))*np.log10(d_km)

# -------------------------------
# 6Ô∏è‚É£ MACHINE LEARNING
# -------------------------------
le = LabelEncoder()
df['gw_id_enc'] = le.fit_transform(df['gw_id'].astype(str))
features = ['dist_m','hour','dayofweek','gw_id_enc']
X = df[features].fillna(0)
y = -df['best_rssi']

# Valida√ß√£o espacial (GroupKFold por gateway)
groups = df['gw_id_enc']
gkf = GroupKFold(n_splits=5)
rf_scores, xgb_scores = [], []

for train_idx, test_idx in gkf.split(X, y, groups):
    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]
    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]

    rf = RandomForestRegressor(n_estimators=200, random_state=42).fit(X_train, y_train)
    xgb = XGBRegressor(n_estimators=200, random_state=42).fit(X_train, y_train)

    for model, scores in zip([rf,xgb],[rf_scores,xgb_scores]):
        y_pred = model.predict(X_test)
        rmse = np.sqrt(mean_squared_error(y_test, y_pred))
        mae = mean_absolute_error(y_test, y_pred)
        r2 = r2_score(y_test, y_pred)
        scores.append([rmse, mae, r2])

print("RF scores (5-fold):", np.mean(rf_scores,axis=0))
print("XGB scores (5-fold):", np.mean(xgb_scores,axis=0))

# -------------------------------
# 7Ô∏è‚É£ TREINAR MODELO FINAL PARA MAPA DE ERRO
# -------------------------------
rf_final = RandomForestRegressor(n_estimators=200, random_state=42)
rf_final.fit(X, y)

df['err_rf'] = y - rf_final.predict(X)

# -------------------------------
# 8Ô∏è‚É£ ABLATION STUDY
# -------------------------------
ablation_sets = {
    "no_gw": ['dist_m','hour','dayofweek'],
    "only_dist": ['dist_m']
}

for name, feats in ablation_sets.items():
    X_ab = X[feats]
    rf = RandomForestRegressor(n_estimators=200, random_state=42).fit(X_ab, y)
    y_pred = rf.predict(X_ab)
    rmse = np.sqrt(mean_squared_error(y, y_pred))
    print(f"Ablation {name} RMSE: {rmse:.2f}")

# -------------------------------
# 9Ô∏è‚É£ MAPA DE ERRO GEOGR√ÅFICO
# -------------------------------
plt.figure(figsize=(8,6))
plt.scatter(df['Longitude'], df['Latitude'], c=df['err_rf'], cmap='RdBu', s=10)
plt.colorbar(label='Erro RF [dB]')
plt.xlabel('Longitude')
plt.ylabel('Latitude')
plt.title('Mapa de erro geogr√°fico ‚Äì RF')
plt.show()

# -------------------------------
# üîü HISTOGRAMA DE ERRO POR DIST√ÇNCIA
# -------------------------------
plt.figure(figsize=(8,6))
plt.hist(df['err_rf'], bins=50, color='skyblue', edgecolor='k')
plt.xlabel('Erro RF [dB]')
plt.ylabel('N√∫mero de amostras')
plt.title('Distribui√ß√£o de erro ‚Äì RF')
plt.show()

import matplotlib.pyplot as plt
import numpy as np

# -------------------------------
# 1Ô∏è‚É£ MAPA DE ERRO GEOGR√ÅFICO ‚Äì RF
# -------------------------------
plt.figure(figsize=(8,6))
plt.scatter(df['Longitude'], df['Latitude'], c=df['err_rf'], cmap='RdBu', s=15, alpha=0.7)
plt.colorbar(label='Erro RF [dB]')
plt.xlabel('Longitude')
plt.ylabel('Latitude')
plt.title('Mapa de erro geogr√°fico ‚Äì Random Forest')
plt.show()

# -------------------------------
# 2Ô∏è‚É£ HISTOGRAMA DE ERRO POR DIST√ÇNCIA ‚Äì RF
# -------------------------------
plt.figure(figsize=(8,6))
plt.scatter(df['dist_m'], df['err_rf'], c='skyblue', alpha=0.5, s=10)
plt.axhline(0, color='k', linestyle='--')
plt.xlabel('Dist√¢ncia [m]')
plt.ylabel('Erro RF [dB]')
plt.title('Erro do RF versus dist√¢ncia')
plt.show()

# Histograma
plt.figure(figsize=(8,6))
plt.hist(df['err_rf'], bins=50, color='lightcoral', edgecolor='k')
plt.xlabel('Erro RF [dB]')
plt.ylabel('N√∫mero de amostras')
plt.title('Distribui√ß√£o de erro ‚Äì Random Forest')
plt.show()

# -------------------------------
# 3Ô∏è‚É£ COMPARA√á√ÉO COM BASELINES FSPL / OKUMURA-HATA
# -------------------------------
# Erros
df['err_fspl'] = -df['best_rssi'] - df['fspl_db']
df['err_ohata'] = -df['best_rssi'] - df['ohata']

plt.figure(figsize=(8,6))
plt.boxplot([df['err_rf'], df['err_fspl'], df['err_ohata']], labels=['RF', 'FSPL', 'Okumura-Hata'])
plt.ylabel('Erro [dB]')
plt.title('Compara√ß√£o de erro entre modelos')
plt.show()

# -------------------------------
# 4Ô∏è‚É£ CONCLUS√ïES CURTAS (exemplo)
# -------------------------------
print("‚úÖ Conclus√µes preliminares:")
print("1. RF captura bem varia√ß√µes espaciais, mas apresenta tend√™ncia de subestima√ß√£o em √°reas distantes.")
print("2. FSPL fornece baseline est√°vel com RMSE pr√≥ximo a 12‚Äì13 dB.")
print("3. Okumura-Hata superestima atenua√ß√£o em dist√¢ncias curtas e apresenta RMSE maior (~37 dB).")
print("4. Ablation study mostra que gw_id √© a feature mais relevante; vari√°veis temporais t√™m impacto pequeno.")
print("5. Mapas de erro indicam regi√µes espec√≠ficas de maior desvio, √∫teis para planejamento de rede.")

import pandas as pd
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
import numpy as np

# -------------------------------
# 1Ô∏è‚É£ CALCULAR METRICAS
# -------------------------------
y_true = -df['best_rssi']

metrics = {}
# Random Forest
y_pred_rf = rf_final.predict(X)
metrics['RF'] = {
    'RMSE': np.sqrt(mean_squared_error(y_true, y_pred_rf)),
    'MAE': mean_absolute_error(y_true, y_pred_rf),
    'R¬≤': r2_score(y_true, y_pred_rf)
}

# FSPL
y_pred_fspl = df['fspl_db']
metrics['FSPL'] = {
    'RMSE': np.sqrt(mean_squared_error(y_true, y_pred_fspl)),
    'MAE': mean_absolute_error(y_true, y_pred_fspl),
    'R¬≤': r2_score(y_true, y_pred_fspl)
}

# Okumura-Hata
y_pred_ohata = df['ohata']
metrics['Okumura-Hata'] = {
    'RMSE': np.sqrt(mean_squared_error(y_true, y_pred_ohata)),
    'MAE': mean_absolute_error(y_true, y_pred_ohata),
    'R¬≤': r2_score(y_true, y_pred_ohata)
}

# -------------------------------
# 2Ô∏è‚É£ CRIAR DATAFRAME COMPARATIVO
# -------------------------------
df_compare = pd.DataFrame(metrics).T
df_compare = df_compare[['RMSE','MAE','R¬≤']]  # Ordenar colunas
df_compare = df_compare.round(2)

# Exibir tabela
print("üìä Tabela comparativa de desempenho dos modelos:")
display(df_compare)

import matplotlib.pyplot as plt

fig, ax = plt.subplots(figsize=(6,2))
ax.axis('off')

table = ax.table(
    cellText=df_compare.values,
    colLabels=df_compare.columns,
    rowLabels=df_compare.index,
    cellLoc='center',
    loc='center'
)

table.auto_set_font_size(False)
table.set_fontsize(12)
table.scale(1, 1.5)

# Destacar melhores c√©lulas
for i, col in enumerate(df_compare.columns):
    if col == 'R¬≤':
        best_idx_label = df_compare[col].idxmax()  # √≠ndice do DataFrame
    else:
        best_idx_label = df_compare[col].idxmin()
    best_idx_pos = df_compare.index.get_loc(best_idx_label)  # converte para posi√ß√£o num√©rica
    cell = table[best_idx_pos, i]
    cell.set_facecolor('lightgreen')

plt.title("Desempenho comparativo dos modelos", fontsize=14)
plt.show()